# ==============================================================================
# Image Classification Configuration
# ==============================================================================
# Configuration file for initializing an annotation session for image
# classification tasks.
#
# This configuration sets up the data paths, feature extraction parameters,
# and ML training parameters for the active annotation workflow.
# ==============================================================================

# ==============================================================================
# TASK TYPE
# ==============================================================================
# The type of annotation task for this session
# Options:
#   - "segmentation": Point-based annotation for binary/multi-class segmentation
#   - "classification": Image-level classification with class labels

task: "classification"

# ==============================================================================
# DATA PATHS
# ==============================================================================

# Path to directory containing input images
# The script will recursively search this directory for images matching the
# specified formats below.
image_dir: "/Users/houtj/projects/active_annotation/data/img_samples"

# Comma-separated list of image file formats to process
# Common formats: png, jpg, jpeg, tif, tiff
# The script will search for both lowercase and uppercase extensions
formats: "jpg,jpeg,png"

# Optional: Path to directory containing pre-existing label JSON files
# For classification, labels should contain {"type": "class", "classname": "..."}
# Set to null or empty string if no labels are available
labels_dir: null

# Optional: Maximum number of image files to process
# Useful for testing or working with a subset of data
# Set to null to process all images
max_files: null


# ==============================================================================
# SESSION AND MODEL PATHS
# ==============================================================================

# These paths are relative to the project root and typically don't need changes
# unless you have a custom directory structure

# Session directory where annotations, features, and checkpoints are stored
# Default: ../session (relative to initialization folder)
session_dir: "../session"

# Path to DINOv3 model repository
# Default: ../models/dinov3 (relative to initialization folder)
dinov3_repo: "../models/dinov3"

# Path to DINOv3 pretrained weights
# Default: ../models/weights/dinov3_vits16_pretrain_lvd1689m-08c60483.pth
weights_path: "../models/weights/dinov3_vits16_pretrain_lvd1689m-08c60483.pth"


# ==============================================================================
# FEATURE EXTRACTION
# ==============================================================================

# Target size for DINOv3 feature extraction (in pixels)
# Images are resized so their largest dimension equals this value, then
# zero-padded to a square. The value must be a multiple of 16 (DINOv3 patch size).
# 
# Guidelines:
#   - Higher values preserve more detail but increase memory and computation
#   - 1536 is recommended for high-resolution images
#   - 1024 works well for medium-resolution images
#   - 512 for lower-resolution or faster processing
resize: 1536


# ==============================================================================
# CLASS DEFINITIONS
# ==============================================================================

# Classification classes for image categorization
# Each class has a name and color (hex format) for visualization
# Users will select one class per image

classes:
  - name: "animal"
    color: "#4CAF50"  # Green - represents animals
    
  - name: "car"
    color: "#2196F3"  # Blue - represents vehicles/cars
    
  - name: "human"
    color: "#FF9800"  # Orange - represents people
    
  - name: "other"
    color: "#9E9E9E"  # Grey - represents other/unknown categories


# ==============================================================================
# ML TRAINING PARAMETERS
# ==============================================================================

# Number of training epochs between generating predictions on all files
# During training, the model will generate predictions periodically to provide
# feedback to the user. Lower values = more frequent predictions but slower training.
# Typical range: 10-50
prediction_interval: 20

# Number of epochs to wait for improvement before early stopping
# Training stops if the test loss doesn't improve for this many epochs
# Higher values give more time for convergence but may overtrain
# Typical range: 3-10
early_stop_patience: 5

# Minimum improvement threshold for early stopping
# Only improvements greater than this value count as "real" improvements
# Prevents stopping due to tiny fluctuations in loss
# Typical range: 0.0001 - 0.01
early_stop_threshold: 0.001


# ==============================================================================
# NOTES FOR IMAGE CLASSIFICATION TASKS
# ==============================================================================
# 
# Image classification involves assigning a single class label to each image.
# Key considerations:
#
# 1. FEATURE EXTRACTION:
#    - DINOv3 features are excellent for classification
#    - The full feature map is pooled (global average pooling) for classification
#    - resize=1536 works well for most images
#
# 2. TRAINING:
#    - Uses CrossEntropy loss for multi-class classification
#    - Class weights are computed automatically to handle imbalanced datasets
#    - Batching is image-based (not point-based like segmentation)
#
# 3. LABELING WORKFLOW:
#    - Users simply click on a class to assign it to the current image
#    - Predictions show the model's top class with confidence scores
#    - Model predictions can help speed up labeling
#
# 4. DATA ORGANIZATION:
#    - Organize images in a flat or nested directory structure
#    - Common formats: jpg, jpeg, png
#    - No mask labels needed - just class assignments
#
# ==============================================================================
